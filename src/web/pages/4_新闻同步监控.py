#!/usr/bin/env python3
"""
æ–°é—»åŒæ­¥ç›‘æ§é¡µé¢ - çº¯Streamlitç‰ˆæœ¬
ç›´æ¥è¿æ¥MongoDBï¼Œä¸ä¾èµ–FastAPI
"""
import streamlit as st
import pandas as pd
from datetime import datetime, timedelta, timezone
import plotly.express as px
from pymongo import MongoClient
import os

# åŒ—äº¬æ—¶åŒº (UTC+8)
BEIJING_TZ = timezone(timedelta(hours=8))

def utc_to_beijing(utc_time):
    """å°†UTCæ—¶é—´è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´"""
    if utc_time is None:
        return None
    if utc_time.tzinfo is None:
        utc_time = utc_time.replace(tzinfo=timezone.utc)
    return utc_time.astimezone(BEIJING_TZ)


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ–°é—»åŒæ­¥ç›‘æ§",
    page_icon="ğŸ“°",
    layout="wide"
)

# MongoDBè¿æ¥
@st.cache_resource
def get_mongo_client():
    """è·å–MongoDBå®¢æˆ·ç«¯"""
    mongo_uri = "mongodb://admin:tradingagents123@mongodb:27017/?authSource=admin"
    return MongoClient(mongo_uri, serverSelectionTimeoutMS=5000)

def get_db():
    """è·å–æ•°æ®åº“"""
    client = get_mongo_client()
    return client.tradingagents

# è·å–ç»Ÿè®¡æ•°æ®
def get_news_stats():
    """è·å–æ–°é—»ç»Ÿè®¡æ€»è§ˆ"""
    db = get_db()
    
    # æ€»æ–°é—»æ•°
    total_news = db.stock_news.count_documents({})
    
    # ä»Šæ—¥æ–°å¢
    yesterday = datetime.utcnow() - timedelta(days=1)
    today_news = db.stock_news.count_documents({"created_at": {"$gte": yesterday}})
    
    # è‡ªé€‰è‚¡æ•°é‡
    watchlist_count = db.user_favorites.count_documents({})
    
    # æœ€è¿‘åŒæ­¥æ—¶é—´
    last_sync = db.news_sync_history.find_one({}, sort=[("sync_time", -1)])
    last_sync_time = "æœªçŸ¥"
    if last_sync and last_sync.get("sync_time"):
        delta = datetime.utcnow() - last_sync["sync_time"]
        hours = int(delta.total_seconds() / 3600)
        if hours < 1:
            minutes = int(delta.total_seconds() / 60)
            last_sync_time = f"{minutes}åˆ†é’Ÿå‰"
        elif hours < 24:
            last_sync_time = f"{hours}å°æ—¶å‰"
        else:
            days = int(hours / 24)
            last_sync_time = f"{days}å¤©å‰"
    
    return {
        "total_news": total_news,
        "today_news": today_news,
        "watchlist_count": watchlist_count,
        "last_sync_time": last_sync_time
    }

def get_source_icon(source_type):
    """è·å–æ¥æºå›¾æ ‡"""
    icons = {
        "scraper": "ğŸ•·ï¸ çˆ¬è™«",
        "akshare": "âš¡ AKShare",
        "rss": "ğŸ“¡ RSS",
        "finnhub": "ğŸ‡ºğŸ‡¸ FinnHub",
        "alpha_vantage": "ğŸ…°ï¸ AlphaV",
        "unknown": "â“ æœªçŸ¥"
    }
    # æ¨¡ç³ŠåŒ¹é…
    if "scraper" in str(source_type).lower(): return icons["scraper"]
    if "akshare" in str(source_type).lower(): return icons["akshare"]
    if "rss" in str(source_type).lower(): return icons["rss"]
    return icons.get(source_type, f"ğŸ“ {source_type}")

def get_source_stats():
    """è·å–å„æºç»Ÿè®¡"""
    db = get_db()
    
    # èšåˆï¼šä¼˜å…ˆä½¿ç”¨ source_typeï¼Œå¦‚æœä¸ºç©ºåˆ™å›é€€åˆ° source
    pipeline = [
        {
            "$group": {
                "_id": {"$ifNull": ["$source_type", "$source"]}, 
                "count": {"$sum": 1}
            }
        },
        {"$sort": {"count": -1}}
    ]
    
    sources = []
    total = 0
    for item in db.stock_news.aggregate(pipeline):
        count = item["count"]
        total += count
        raw_source = item["_id"] or "unknown"
        display_source = get_source_icon(raw_source)
        sources.append({"source": display_source, "count": count})
    
    for s in sources:
        s["percentage"] = round(s["count"] / total * 100, 1) if total > 0 else 0
    
    return sources

def get_watchlist_stats():
    """è·å–watchlistç»Ÿè®¡"""
    db = get_db()
    
    # è·å–æ‰€æœ‰è‡ªé€‰è‚¡ï¼ˆå»é‡ï¼‰
    seen_codes = set()
    stocks = []
    
    for doc in db.user_favorites.find({}):
        for fav in doc.get("favorites", []):
            code = fav.get("stock_code")
            name = fav.get("stock_name", code)
            
            # å»é‡
            if code and code not in seen_codes:
                seen_codes.add(code)
                
                # æŸ¥è¯¢æ–°é—»æ•°é‡
                total_count = db.stock_news.count_documents({"symbol": code})
                week_ago = datetime.utcnow() - timedelta(days=7)
                recent_count = db.stock_news.count_documents({
                    "symbol": code,
                    "created_at": {"$gte": week_ago}
                })
                
                stocks.append({
                    "code": code,
                    "name": name,
                    "total_count": total_count,
                    "recent_count": recent_count,
                    "status": "âœ…" if total_count > 10 else "âš ï¸"
                })
    
    return sorted(stocks, key=lambda x: x["total_count"], reverse=True)

def get_sync_history():
    """è·å–åŒæ­¥å†å²"""
    db = get_db()
    history = []
    
    for record in db.news_sync_history.find({}).sort("sync_time", -1).limit(10):
        sync_time = record.get("sync_time")
        if sync_time:
            # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
            beijing_time = utc_to_beijing(sync_time)
            time_str = beijing_time.strftime("%Y-%m-%d %H:%M") + " (åŒ—äº¬æ—¶é—´)"
        else:
            time_str = "N/A"
            
        # æ ¼å¼åŒ–æ–°é—»æ•°ï¼šæ–°å¢ (æŠ“å–)
        news_count_display = f"{record.get('news_count', 0)}"
        if 'fetched_count' in record:
            news_count_display += f" (æŠ“{record.get('fetched_count', 0)})"
            
        history.append({
            "sync_time": time_str,
            "sync_type": record.get("sync_type", "unknown"),
            "status": record.get("status", "unknown"),
            "news_count_display": news_count_display,  # ä½¿ç”¨æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
            "duration": round(record.get("duration", 0), 1)
        })
    
    return history

# æ ‡é¢˜
st.title("ğŸ“° æ–°é—»åŒæ­¥ç›‘æ§")
st.markdown("---")

# æ‰‹åŠ¨åŒæ­¥å‡½æ•° (é€šç”¨)
def run_sync_script(script_path, timeout=120, async_mode=False):
    """è¿è¡ŒæŒ‡å®šçš„åŒæ­¥è„šæœ¬"""
    import subprocess
    import json
    import sys
    
    # ç¡®ä¿ä½¿ç”¨å½“å‰Pythonè§£é‡Šå™¨
    python_executable = sys.executable
    
    # å¼‚æ­¥æ¨¡å¼ï¼šåå°è¿è¡Œï¼Œç«‹å³è¿”å›
    if async_mode:
        try:
            # ä½¿ç”¨ subprocess.Popen å¯åŠ¨åå°è¿›ç¨‹
            # stdout/stderr é‡å®šå‘åˆ° /dev/null æˆ–ä¸´æ—¶æ–‡ä»¶ï¼Œé˜²æ­¢ç¼“å†²åŒºæ»¡é˜»å¡
            subprocess.Popen(
                [python_executable, script_path],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                preexec_fn=os.setsid  # åˆ›å»ºæ–°ä¼šè¯ï¼Œè„±ç¦»çˆ¶è¿›ç¨‹
            )
            return {"success": True, "message": "å·²åœ¨åå°å¯åŠ¨åŒæ­¥ä»»åŠ¡", "async": True}
        except Exception as e:
            raise Exception(f"å¯åŠ¨åå°ä»»åŠ¡å¤±è´¥: {str(e)}")

    # åŒæ­¥æ¨¡å¼ï¼šç­‰å¾…ç»“æœ
    result = subprocess.run(
        [python_executable, script_path],
        capture_output=True,
        text=True,
        timeout=timeout
    )
    
    if result.returncode != 0:
        error_msg = result.stderr or result.stdout or "æœªçŸ¥é”™è¯¯"
        raise Exception(f"è„šæœ¬æ‰§è¡Œå¤±è´¥: {error_msg}")
    
    try:
        # è·å–æœ€åä¸€è¡Œéç©ºè¾“å‡º
        lines = [line.strip() for line in result.stdout.strip().split('\n') if line.strip()]
        if not lines:
            raise Exception("è„šæœ¬æ— è¾“å‡º")
        
        # è§£ææœ€åä¸€è¡ŒJSON
        data = json.loads(lines[-1])
        if not data.get("success"):
            raise Exception(data.get("error", "åŒæ­¥å¤±è´¥"))
        return data
    except json.JSONDecodeError:
        raise Exception(f"æ— æ³•è§£æç»“æœ: {result.stdout}")

def trigger_akshare_sync():
    return run_sync_script("/app/app/scheduler/manual_sync.py")

def trigger_scraper_sync():
    # çˆ¬è™«æŠ“å–æ”¹ä¸ºå¼‚æ­¥æ¨¡å¼ï¼Œé¿å…å‰ç«¯è¶…æ—¶
    return run_sync_script("/app/app/scheduler/manual_scraper_sync.py", async_mode=True)

def trigger_multisource_sync():
    # å¤šæºèšåˆä¹Ÿæ”¹ä¸ºå¼‚æ­¥æ¨¡å¼
    return run_sync_script("/app/app/scheduler/manual_multisource_sync.py", async_mode=True)


# æ“ä½œæŒ‰é’®åŒº
st.subheader("ğŸ› ï¸ ç«‹å³æ‰§è¡Œ")
col_refresh, col_ak, col_scraper, col_multi, col_empty = st.columns([1, 1.2, 1.2, 1.2, 4])

with col_refresh:
    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®", use_container_width=True):
        st.cache_resource.clear()
        st.rerun()

with col_ak:
    if st.button("âš¡ AKShareå¿«è®¯", use_container_width=True, help="åŒæ­¥AKShareè´¢ç»å¿«è®¯"):
        with st.spinner("æ­£åœ¨åŒæ­¥è´¢ç»å¿«è®¯..."):
            try:
                result = trigger_akshare_sync()
                st.success(f"âœ… å®Œæˆ! +{result.get('news_count', 0)}æ¡")
                st.cache_resource.clear()
                st.rerun()
            except Exception as e:
                st.error(f"âŒ å¤±è´¥: {str(e)}")

with col_scraper:
    if st.button("ğŸ•·ï¸ çˆ¬è™«æŠ“å–", use_container_width=True, help="è¿è¡ŒPlaywrightOCRæŠ“å–è‡ªé€‰è‚¡"):
        with st.spinner("æ­£åœ¨è¿è¡Œçˆ¬è™«æŠ“å–..."):
            try:
                result = trigger_scraper_sync()
                if result.get("async"):
                    st.success("ğŸš€ å·²åœ¨åå°å¯åŠ¨! è¯·æŸ¥çœ‹åŒæ­¥å†å²æˆ–ç¨ååˆ·æ–°ç›‘æ§")
                else:
                    st.success(f"âœ… å®Œæˆ! +{result.get('news_count', 0)}æ¡")
                st.cache_resource.clear()
                st.rerun()
            except Exception as e:
                st.error(f"âŒ å¤±è´¥: {str(e)}")

with col_multi:
    if st.button("ğŸŒ å¤šæºèšåˆ", use_container_width=True, help="è¿è¡Œå¤šæº(RSS/AlphaVantageç­‰)èšåˆ"):
        with st.spinner("æ­£åœ¨è¿è¡Œå¤šæºèšåˆ..."):
            try:
                result = trigger_multisource_sync()
                if result.get("async"):
                    st.success("ğŸš€ å·²åœ¨åå°å¯åŠ¨! è¯·æŸ¥çœ‹åŒæ­¥å†å²æˆ–ç¨ååˆ·æ–°ç›‘æ§")
                else:
                    st.success(f"âœ… å®Œæˆ! +{result.get('news_count', 0)}æ¡")
                st.cache_resource.clear()
                st.rerun()
            except Exception as e:
                st.error(f"âŒ å¤±è´¥: {str(e)}")


# è·å–æ•°æ®
try:
    stats = get_news_stats()
    source_stats = get_source_stats()
    watchlist_stats = get_watchlist_stats()
    sync_history = get_sync_history()
    
    # æ€»è§ˆç»Ÿè®¡
    st.subheader("ğŸ“Š æ€»è§ˆç»Ÿè®¡")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æ€»æ–°é—»æ•°", f"{stats['total_news']:,}")
    
    with col2:
        st.metric("ä»Šæ—¥æ–°å¢", f"{stats['today_news']:,}")
    
    with col3:
        st.metric("è‡ªé€‰è‚¡æ•°", stats['watchlist_count'])
    
    with col4:
        st.metric("æœ€è¿‘åŒæ­¥", stats['last_sync_time'])
    
    st.markdown("---")
    
    # ä¸¤åˆ—å¸ƒå±€
    col_left, col_right = st.columns([1, 1])
    
    # å·¦åˆ—ï¼šå„æºç»Ÿè®¡
    with col_left:
        st.subheader("ğŸ“ˆ å„æºç»Ÿè®¡")
        
        if source_stats:
            df_sources = pd.DataFrame(source_stats)
            
            st.dataframe(
                df_sources,
                column_config={
                    "source": st.column_config.TextColumn("æ–°é—»æº", width="medium"),
                    "count": st.column_config.NumberColumn("æ–°é—»æ•°", format="%d"),
                    "percentage": st.column_config.NumberColumn("å æ¯”", format="%.1f%%")
                },
                hide_index=True,
                use_container_width=True
            )
            
            # é¥¼å›¾
            fig = px.pie(df_sources, values='count', names='source', title='æ–°é—»æºåˆ†å¸ƒ')
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("æš‚æ— æ•°æ®")
    
    # å³åˆ—ï¼šè‡ªé€‰è‚¡ç»Ÿè®¡
    with col_right:
        st.subheader("ğŸ“‹ è‡ªé€‰è‚¡æ–°é—»ç»Ÿè®¡")
        
        if watchlist_stats:
            df_stocks = pd.DataFrame(watchlist_stats)
            
            st.dataframe(
                df_stocks,
                column_config={
                    "code": st.column_config.TextColumn("ä»£ç ", width="small"),
                    "name": st.column_config.TextColumn("åç§°", width="medium"),
                    "total_count": st.column_config.NumberColumn("æ€»æ•°", format="%d"),
                    "recent_count": st.column_config.NumberColumn("è¿‘7å¤©", format="%d"),
                    "status": st.column_config.TextColumn("çŠ¶æ€", width="small")
                },
                hide_index=True,
                use_container_width=True
            )
            
            # æŸ±çŠ¶å›¾
            fig = px.bar(df_stocks, x='code', y='total_count', 
                        title='å„è‚¡ç¥¨æ–°é—»æ•°é‡',
                        labels={'code': 'è‚¡ç¥¨ä»£ç ', 'total_count': 'æ–°é—»æ•°é‡'})
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("æš‚æ— è‡ªé€‰è‚¡æ•°æ®")
    
    st.markdown("---")
    
    # åŒæ­¥å†å²
    st.subheader("ğŸ“œ åŒæ­¥å†å²")
    
    if sync_history:
        df_history = pd.DataFrame(sync_history)
        
        st.dataframe(
            df_history,
            column_config={
                "sync_time": st.column_config.TextColumn("åŒæ­¥æ—¶é—´", width="medium"),
                "sync_type": st.column_config.TextColumn("ç±»å‹", width="small"),
                "status": st.column_config.TextColumn("çŠ¶æ€", width="small"),
                "news_count_display": st.column_config.TextColumn("æ–°å¢ (æŠ“å–)", width="small"),
                "duration": st.column_config.NumberColumn("è€—æ—¶(ç§’)", format="%.1f")
            },
            hide_index=True,
            use_container_width=True
        )
    else:
        st.info("æš‚æ— åŒæ­¥å†å²è®°å½•")
    
    # é¡µè„š
    st.markdown("---")
    st.caption("ğŸ’¡ æç¤ºï¼šç‚¹å‡»ã€Œåˆ·æ–°æ•°æ®ã€æŒ‰é’®æ›´æ–°ç»Ÿè®¡ä¿¡æ¯")
    
except Exception as e:
    st.error(f"âš ï¸ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
    st.info("è¯·æ£€æŸ¥MongoDBè¿æ¥æ˜¯å¦æ­£å¸¸")
