#!/usr/bin/env python3
"""
æ¸¯è‚¡æ²½ç©ºæ•°æ®æ¨¡å—
ä»æ¸¯äº¤æ‰€/ä¸œæ–¹è´¢å¯Œè·å–æ¯æ—¥æ²½ç©ºæ•°æ®ï¼Œæ”¯æŒå†å²æ•°æ®ç§¯ç´¯å’ŒæŸ¥è¯¢

æ•°æ®æºä¼˜å…ˆçº§ï¼š
1. ä¸œæ–¹è´¢å¯Œ APIï¼ˆä¸»è¦æ•°æ®æºï¼Œæ•°æ®å®Œæ•´ï¼‰
2. æ¸¯äº¤æ‰€å®˜ç½‘ï¼ˆå¤‡ç”¨æ•°æ®æºï¼‰
"""

import os
import time
import json
import re
import threading
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List, Set, Callable

import requests
from bs4 import BeautifulSoup

# å¯¼å…¥ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
try:
    from tradingagents.utils.logging_init import get_logger
    logger = get_logger("default")
except ImportError:
    import logging
    logger = logging.getLogger(__name__)

# å¯¼å…¥è¿è¡Œæ—¶é…ç½®
try:
    from tradingagents.config.runtime_settings import get_int, get_float
except ImportError:
    def get_int(env_key, config_key, default):
        return int(os.environ.get(env_key, default))
    def get_float(env_key, config_key, default):
        return float(os.environ.get(env_key, default))


# ============================================================================
# æ•°æ®æ¨¡å‹
# ============================================================================

@dataclass
class ShortSellingRecord:
    """æ²½ç©ºè®°å½•æ•°æ®æ¨¡å‹"""
    
    stock_code: str          # è‚¡ç¥¨ä»£ç ï¼ˆ5ä½æ ¼å¼ï¼Œå¦‚ "00700"ï¼‰
    stock_name: str          # è‚¡ç¥¨åç§°
    date: str                # æ—¥æœŸï¼ˆYYYY-MM-DD æ ¼å¼ï¼‰
    short_shares: int        # æ²½ç©ºè‚¡æ•°
    short_value: float       # æ²½ç©ºé‡‘é¢ï¼ˆæ¸¯å…ƒï¼‰
    short_ratio: float       # æ²½ç©ºæ¯”ä¾‹ï¼ˆå°æ•°ï¼Œå¦‚ 0.0523 è¡¨ç¤º 5.23%ï¼‰
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)
    
    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "stock_code": self.stock_code,
            "stock_name": self.stock_name,
            "date": self.date,
            "short_shares": self.short_shares,
            "short_value": self.short_value,
            "short_ratio": self.short_ratio,
            "created_at": self.created_at.isoformat() if isinstance(self.created_at, datetime) else self.created_at,
            "updated_at": self.updated_at.isoformat() if isinstance(self.updated_at, datetime) else self.updated_at
        }
    
    @classmethod
    def from_dict(cls, data: dict) -> "ShortSellingRecord":
        """ä»å­—å…¸åˆ›å»ºå®ä¾‹"""
        created_at = data.get("created_at")
        updated_at = data.get("updated_at")
        
        if isinstance(created_at, str):
            created_at = datetime.fromisoformat(created_at)
        elif created_at is None:
            created_at = datetime.now()
            
        if isinstance(updated_at, str):
            updated_at = datetime.fromisoformat(updated_at)
        elif updated_at is None:
            updated_at = datetime.now()
        
        return cls(
            stock_code=data["stock_code"],
            stock_name=data["stock_name"],
            date=data["date"],
            short_shares=int(data["short_shares"]),
            short_value=float(data["short_value"]),
            short_ratio=float(data["short_ratio"]),
            created_at=created_at,
            updated_at=updated_at
        )


# ============================================================================
# HTML è§£æå™¨
# ============================================================================

class HKEXShortSellingParser:
    """æ¸¯äº¤æ‰€æ²½ç©ºæŠ¥å‘Š HTML è§£æå™¨"""
    
    def parse(self, html_content: str, date: str) -> List[ShortSellingRecord]:
        """
        è§£æ HTML å†…å®¹æå–æ²½ç©ºè®°å½•
        
        Args:
            html_content: HTML å­—ç¬¦ä¸²
            date: æ•°æ®æ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            è§£æåçš„æ²½ç©ºè®°å½•åˆ—è¡¨
        """
        records = []
        now = datetime.now()
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # æŸ¥æ‰¾æ•°æ®è¡¨æ ¼
            tables = soup.find_all('table')
            
            for table in tables:
                rows = table.find_all('tr')
                
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    
                    # è·³è¿‡è¡¨å¤´è¡Œ
                    if len(cells) < 5:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°æ®è¡Œï¼ˆç¬¬ä¸€åˆ—åº”è¯¥æ˜¯è‚¡ç¥¨ä»£ç ï¼‰
                    first_cell = cells[0].get_text(strip=True)
                    if not first_cell or not first_cell.replace('.', '').isdigit():
                        continue
                    
                    try:
                        # è§£æå„å­—æ®µ
                        stock_code = self._normalize_stock_code(first_cell)
                        stock_name = cells[1].get_text(strip=True) if len(cells) > 1 else ""
                        
                        # æ²½ç©ºè‚¡æ•°ï¼ˆç¬¬3åˆ—ï¼‰
                        short_shares_str = cells[2].get_text(strip=True) if len(cells) > 2 else "0"
                        short_shares = self._parse_numeric(short_shares_str)
                        
                        # æ²½ç©ºé‡‘é¢ï¼ˆç¬¬4åˆ—ï¼‰
                        short_value_str = cells[3].get_text(strip=True) if len(cells) > 3 else "0"
                        short_value = self._parse_numeric(short_value_str)
                        
                        # æ²½ç©ºæ¯”ä¾‹ï¼ˆç¬¬5åˆ—ï¼‰
                        short_ratio_str = cells[4].get_text(strip=True) if len(cells) > 4 else "0%"
                        short_ratio = self._parse_ratio(short_ratio_str)
                        
                        if short_shares is None or short_value is None or short_ratio is None:
                            logger.warning(f"âš ï¸ [æ²½ç©ºè§£æ] è·³è¿‡æ— æ•ˆè®°å½•: {stock_code}")
                            continue
                        
                        record = ShortSellingRecord(
                            stock_code=stock_code,
                            stock_name=stock_name,
                            date=date,
                            short_shares=int(short_shares),
                            short_value=float(short_value),
                            short_ratio=float(short_ratio),
                            created_at=now,
                            updated_at=now
                        )
                        records.append(record)
                        
                    except Exception as e:
                        logger.warning(f"âš ï¸ [æ²½ç©ºè§£æ] è§£æè¡Œå¤±è´¥: {e}")
                        continue
            
            logger.info(f"âœ… [æ²½ç©ºè§£æ] æˆåŠŸè§£æ {len(records)} æ¡è®°å½•")
            
        except Exception as e:
            logger.error(f"âŒ [æ²½ç©ºè§£æ] HTML è§£æå¤±è´¥: {e}")
        
        return records
    
    def _normalize_stock_code(self, code: str) -> str:
        """
        æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ä¸º 5 ä½æ ¼å¼
        
        Args:
            code: åŸå§‹è‚¡ç¥¨ä»£ç 
            
        Returns:
            5 ä½æ ¼å¼çš„è‚¡ç¥¨ä»£ç 
        """
        # ç§»é™¤éæ•°å­—å­—ç¬¦
        clean_code = re.sub(r'[^\d]', '', code)
        
        # è¡¥é½åˆ° 5 ä½
        return clean_code.zfill(5)
    
    def _parse_numeric(self, value: str) -> Optional[float]:
        """
        è§£ææ•°å€¼å­—ç¬¦ä¸²ï¼Œå¤„ç†é€—å·åˆ†éš”ç¬¦
        
        Args:
            value: æ•°å€¼å­—ç¬¦ä¸²ï¼ˆå¦‚ "1,234,567"ï¼‰
            
        Returns:
            è§£æåçš„æ•°å€¼ï¼Œå¤±è´¥è¿”å› None
        """
        if not value:
            return None
        
        try:
            # ç§»é™¤é€—å·å’Œç©ºæ ¼
            clean_value = value.replace(',', '').replace(' ', '').strip()
            
            # å¤„ç†ç©ºå­—ç¬¦ä¸²
            if not clean_value or clean_value == '-':
                return 0.0
            
            return float(clean_value)
        except (ValueError, TypeError):
            return None
    
    def _parse_ratio(self, value: str) -> Optional[float]:
        """
        è§£æç™¾åˆ†æ¯”å­—ç¬¦ä¸²ä¸ºå°æ•°
        
        Args:
            value: ç™¾åˆ†æ¯”å­—ç¬¦ä¸²ï¼ˆå¦‚ "5.23%"ï¼‰
            
        Returns:
            å°æ•°å€¼ï¼ˆå¦‚ 0.0523ï¼‰ï¼Œå¤±è´¥è¿”å› None
        """
        if not value:
            return None
        
        try:
            # ç§»é™¤ç™¾åˆ†å·å’Œç©ºæ ¼
            clean_value = value.replace('%', '').replace(' ', '').strip()
            
            # å¤„ç†ç©ºå­—ç¬¦ä¸²
            if not clean_value or clean_value == '-':
                return 0.0
            
            # è½¬æ¢ä¸ºå°æ•°
            return float(clean_value) / 100.0
        except (ValueError, TypeError):
            return None


# ============================================================================
# é€Ÿç‡é™åˆ¶å™¨
# ============================================================================

class RateLimiter:
    """é€Ÿç‡é™åˆ¶å™¨"""
    
    def __init__(self, min_interval: float = None):
        """
        åˆå§‹åŒ–é€Ÿç‡é™åˆ¶å™¨
        
        Args:
            min_interval: æœ€å°è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–
        """
        if min_interval is None:
            min_interval = get_float(
                "TA_HK_SHORT_RATE_LIMIT_SECONDS",
                "ta_hk_short_rate_limit_seconds",
                5.0
            )
        
        self.min_interval = min_interval
        self.last_request_time = 0.0
        self._lock = threading.Lock()
    
    def acquire(self) -> None:
        """è·å–è¯·æ±‚è®¸å¯ï¼Œå¿…è¦æ—¶ç­‰å¾…"""
        with self._lock:
            current_time = time.time()
            time_since_last = current_time - self.last_request_time
            
            if time_since_last < self.min_interval:
                wait_time = self.min_interval - time_since_last
                logger.debug(f"â±ï¸ [é€Ÿç‡é™åˆ¶] ç­‰å¾… {wait_time:.2f} ç§’")
                time.sleep(wait_time)
            
            self.last_request_time = time.time()
    
    def reset(self) -> None:
        """é‡ç½®é™åˆ¶å™¨çŠ¶æ€"""
        with self._lock:
            self.last_request_time = 0.0


# ============================================================================
# MongoDB å­˜å‚¨å±‚
# ============================================================================

class ShortSellingRepository:
    """æ²½ç©ºæ•°æ® MongoDB å­˜å‚¨å±‚"""
    
    COLLECTION_NAME = "hk_short_selling"
    
    def __init__(self, db_client=None):
        """
        åˆå§‹åŒ–å­˜å‚¨å±‚
        
        Args:
            db_client: MongoDB å®¢æˆ·ç«¯ï¼Œå¦‚æœä¸º None åˆ™å°è¯•è‡ªåŠ¨è·å–
        """
        self.db_client = db_client
        self.collection = None
        
        if db_client is not None:
            self._init_collection()
    
    def _init_collection(self):
        """åˆå§‹åŒ–é›†åˆå¹¶åˆ›å»ºç´¢å¼•"""
        if self.db_client is None:
            return
        
        try:
            # è·å–æ•°æ®åº“
            db = self.db_client.get_database()
            self.collection = db[self.COLLECTION_NAME]
            
            # åˆ›å»ºç´¢å¼•
            self.collection.create_index(
                [("stock_code", 1), ("date", 1)],
                unique=True,
                name="idx_stock_date"
            )
            self.collection.create_index([("date", 1)], name="idx_date")
            self.collection.create_index([("short_ratio", -1)], name="idx_ratio")
            
            logger.info(f"âœ… [MongoDB] åˆå§‹åŒ–é›†åˆ {self.COLLECTION_NAME} å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ [MongoDB] åˆå§‹åŒ–é›†åˆå¤±è´¥: {e}")
    
    def set_client(self, db_client):
        """è®¾ç½® MongoDB å®¢æˆ·ç«¯"""
        self.db_client = db_client
        self._init_collection()
    
    def upsert_records(self, records: List[ShortSellingRecord]) -> int:
        """
        æ‰¹é‡æ’å…¥æˆ–æ›´æ–°è®°å½•
        
        Args:
            records: æ²½ç©ºè®°å½•åˆ—è¡¨
            
        Returns:
            å—å½±å“çš„è®°å½•æ•°
        """
        if not self.collection or not records:
            return 0
        
        affected = 0
        now = datetime.now()
        
        try:
            from pymongo import UpdateOne
            
            operations = []
            for record in records:
                doc = record.to_dict()
                doc["updated_at"] = now.isoformat()
                
                operations.append(
                    UpdateOne(
                        {"stock_code": record.stock_code, "date": record.date},
                        {"$set": doc, "$setOnInsert": {"created_at": now.isoformat()}},
                        upsert=True
                    )
                )
            
            if operations:
                result = self.collection.bulk_write(operations)
                affected = result.upserted_count + result.modified_count
                logger.info(f"âœ… [MongoDB] æ‰¹é‡æ›´æ–° {affected} æ¡è®°å½•")
            
        except Exception as e:
            logger.error(f"âŒ [MongoDB] æ‰¹é‡æ›´æ–°å¤±è´¥: {e}")
        
        return affected
    
    def find_by_stock_and_date(self, stock_code: str, date: str) -> Optional[Dict]:
        """æŒ‰è‚¡ç¥¨ä»£ç å’Œæ—¥æœŸæŸ¥è¯¢"""
        if not self.collection:
            return None
        
        try:
            # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
            normalized_code = stock_code.zfill(5)
            
            doc = self.collection.find_one({
                "stock_code": normalized_code,
                "date": date
            })
            
            if doc:
                doc.pop("_id", None)
                return doc
            
        except Exception as e:
            logger.error(f"âŒ [MongoDB] æŸ¥è¯¢å¤±è´¥: {e}")
        
        return None
    
    def find_by_stock_and_date_range(
        self, 
        stock_code: str, 
        start_date: str, 
        end_date: str
    ) -> List[Dict]:
        """æŒ‰è‚¡ç¥¨ä»£ç å’Œæ—¥æœŸèŒƒå›´æŸ¥è¯¢"""
        if not self.collection:
            return []
        
        try:
            normalized_code = stock_code.zfill(5)
            
            cursor = self.collection.find({
                "stock_code": normalized_code,
                "date": {"$gte": start_date, "$lte": end_date}
            }).sort("date", 1)
            
            results = []
            for doc in cursor:
                doc.pop("_id", None)
                results.append(doc)
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ [MongoDB] èŒƒå›´æŸ¥è¯¢å¤±è´¥: {e}")
        
        return []
    
    def find_top_by_ratio(self, date: str, limit: int = 20) -> List[Dict]:
        """æŒ‰æ²½ç©ºæ¯”ä¾‹é™åºæŸ¥è¯¢å‰ N æ¡"""
        if not self.collection:
            return []
        
        try:
            cursor = self.collection.find({
                "date": date
            }).sort("short_ratio", -1).limit(limit)
            
            results = []
            for doc in cursor:
                doc.pop("_id", None)
                results.append(doc)
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ [MongoDB] Top N æŸ¥è¯¢å¤±è´¥: {e}")
        
        return []
    
    def get_dates_with_data(self, start_date: str, end_date: str) -> Set[str]:
        """è·å–æŒ‡å®šèŒƒå›´å†…å·²æœ‰æ•°æ®çš„æ—¥æœŸé›†åˆ"""
        if not self.collection:
            return set()
        
        try:
            cursor = self.collection.distinct("date", {
                "date": {"$gte": start_date, "$lte": end_date}
            })
            
            return set(cursor)
            
        except Exception as e:
            logger.error(f"âŒ [MongoDB] è·å–æ—¥æœŸé›†åˆå¤±è´¥: {e}")
        
        return set()
    
    def get_market_stats(self, date: str) -> Optional[Dict]:
        """è·å–æŒ‡å®šæ—¥æœŸçš„å¸‚åœºç»Ÿè®¡"""
        if not self.collection:
            return None
        
        try:
            pipeline = [
                {"$match": {"date": date}},
                {"$group": {
                    "_id": None,
                    "total_short_shares": {"$sum": "$short_shares"},
                    "total_short_value": {"$sum": "$short_value"},
                    "avg_short_ratio": {"$avg": "$short_ratio"},
                    "max_short_ratio": {"$max": "$short_ratio"},
                    "stock_count": {"$sum": 1}
                }}
            ]
            
            result = list(self.collection.aggregate(pipeline))
            
            if result:
                stats = result[0]
                stats.pop("_id", None)
                stats["date"] = date
                return stats
            
        except Exception as e:
            logger.error(f"âŒ [MongoDB] å¸‚åœºç»Ÿè®¡æŸ¥è¯¢å¤±è´¥: {e}")
        
        return None


# ============================================================================
# Redis ç¼“å­˜å±‚
# ============================================================================

class ShortSellingCache:
    """æ²½ç©ºæ•°æ® Redis ç¼“å­˜å±‚"""
    
    KEY_PREFIX = "hk_short"
    DEFAULT_TTL = 86400  # 24 å°æ—¶
    
    def __init__(self, redis_client=None):
        """
        åˆå§‹åŒ–ç¼“å­˜å±‚
        
        Args:
            redis_client: Redis å®¢æˆ·ç«¯
        """
        self.redis_client = redis_client
    
    def set_client(self, redis_client):
        """è®¾ç½® Redis å®¢æˆ·ç«¯"""
        self.redis_client = redis_client
    
    def _make_key(self, *parts) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return ":".join([self.KEY_PREFIX] + list(parts))
    
    def get_stock_data(self, stock_code: str, date: str) -> Optional[Dict]:
        """è·å–ç¼“å­˜çš„è‚¡ç¥¨æ²½ç©ºæ•°æ®"""
        if not self.redis_client:
            return None
        
        try:
            normalized_code = stock_code.zfill(5)
            key = self._make_key(normalized_code, date)
            
            data = self.redis_client.get(key)
            if data:
                return json.loads(data)
            
        except Exception as e:
            logger.warning(f"âš ï¸ [Redis] è¯»å–ç¼“å­˜å¤±è´¥: {e}")
        
        return None
    
    def set_stock_data(
        self, 
        stock_code: str, 
        date: str, 
        data: Dict,
        ttl: int = None
    ) -> None:
        """ç¼“å­˜è‚¡ç¥¨æ²½ç©ºæ•°æ®"""
        if not self.redis_client:
            return
        
        try:
            normalized_code = stock_code.zfill(5)
            key = self._make_key(normalized_code, date)
            
            self.redis_client.setex(
                key,
                ttl or self.DEFAULT_TTL,
                json.dumps(data, ensure_ascii=False)
            )
            
        except Exception as e:
            logger.warning(f"âš ï¸ [Redis] å†™å…¥ç¼“å­˜å¤±è´¥: {e}")
    
    def get_daily_stats(self, date: str) -> Optional[Dict]:
        """è·å–ç¼“å­˜çš„æ¯æ—¥ç»Ÿè®¡"""
        if not self.redis_client:
            return None
        
        try:
            key = self._make_key("daily", date)
            
            data = self.redis_client.get(key)
            if data:
                return json.loads(data)
            
        except Exception as e:
            logger.warning(f"âš ï¸ [Redis] è¯»å–æ¯æ—¥ç»Ÿè®¡ç¼“å­˜å¤±è´¥: {e}")
        
        return None
    
    def set_daily_stats(self, date: str, stats: Dict, ttl: int = None) -> None:
        """ç¼“å­˜æ¯æ—¥ç»Ÿè®¡"""
        if not self.redis_client:
            return
        
        try:
            key = self._make_key("daily", date)
            
            self.redis_client.setex(
                key,
                ttl or self.DEFAULT_TTL,
                json.dumps(stats, ensure_ascii=False)
            )
            
        except Exception as e:
            logger.warning(f"âš ï¸ [Redis] å†™å…¥æ¯æ—¥ç»Ÿè®¡ç¼“å­˜å¤±è´¥: {e}")
    
    def get_top_stocks(self, date: str, top_n: int) -> Optional[List[Dict]]:
        """è·å–ç¼“å­˜çš„ Top N è‚¡ç¥¨"""
        if not self.redis_client:
            return None
        
        try:
            key = self._make_key("top", date, str(top_n))
            
            data = self.redis_client.get(key)
            if data:
                return json.loads(data)
            
        except Exception as e:
            logger.warning(f"âš ï¸ [Redis] è¯»å– Top N ç¼“å­˜å¤±è´¥: {e}")
        
        return None
    
    def set_top_stocks(self, date: str, top_n: int, stocks: List[Dict], ttl: int = None) -> None:
        """ç¼“å­˜ Top N è‚¡ç¥¨"""
        if not self.redis_client:
            return
        
        try:
            key = self._make_key("top", date, str(top_n))
            
            self.redis_client.setex(
                key,
                ttl or self.DEFAULT_TTL,
                json.dumps(stocks, ensure_ascii=False)
            )
            
        except Exception as e:
            logger.warning(f"âš ï¸ [Redis] å†™å…¥ Top N ç¼“å­˜å¤±è´¥: {e}")
    
    def invalidate_date(self, date: str) -> int:
        """ä½¿æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰ç¼“å­˜å¤±æ•ˆ"""
        if not self.redis_client:
            return 0
        
        try:
            pattern = self._make_key("*", date) + "*"
            keys = list(self.redis_client.scan_iter(match=pattern))
            
            if keys:
                return self.redis_client.delete(*keys)
            
        except Exception as e:
            logger.warning(f"âš ï¸ [Redis] æ¸…é™¤ç¼“å­˜å¤±è´¥: {e}")
        
        return 0


# ============================================================================
# æ ¸å¿ƒæ•°æ®æä¾›å™¨
# ============================================================================

class HKShortSellingProvider:
    """æ¸¯è‚¡æ²½ç©ºæ•°æ®æä¾›å™¨"""
    
    # æ¸¯äº¤æ‰€æ²½ç©ºæ•°æ® URL æ¨¡æ¿
    HKEX_URL_TEMPLATE = "https://www.hkex.com.hk/chi/stat/smstat/ssturnover/ncms/ASHTMAIN_{date}.htm"
    
    # å¤‡ç”¨ URL æ¨¡æ¿
    HKEX_URL_TEMPLATE_ALT = "https://www.hkex.com.hk/eng/stat/smstat/ssturnover/ncms/ASHTMAIN_{date}.htm"
    
    # ä¸œæ–¹è´¢å¯Œ APIï¼ˆä¸»è¦æ•°æ®æºï¼‰
    EASTMONEY_API = "https://datacenter-web.eastmoney.com/api/data/v1/get"
    
    def __init__(
        self,
        mongodb_client=None,
        redis_client=None,
        rate_limiter: RateLimiter = None
    ):
        """
        åˆå§‹åŒ–æä¾›å™¨
        
        Args:
            mongodb_client: MongoDB å®¢æˆ·ç«¯
            redis_client: Redis å®¢æˆ·ç«¯
            rate_limiter: é€Ÿç‡é™åˆ¶å™¨
        """
        self.parser = HKEXShortSellingParser()
        self.repository = ShortSellingRepository(mongodb_client)
        self.cache = ShortSellingCache(redis_client)
        self.rate_limiter = rate_limiter or RateLimiter()
        
        # HTTP è¯·æ±‚é…ç½®
        self.timeout = get_int("TA_HK_SHORT_TIMEOUT", "ta_hk_short_timeout", 30)
        self.max_retries = get_int("TA_HK_SHORT_MAX_RETRIES", "ta_hk_short_max_retries", 3)
        
        # è¯·æ±‚å¤´
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8"
        }
    
    def set_mongodb_client(self, client):
        """è®¾ç½® MongoDB å®¢æˆ·ç«¯"""
        self.repository.set_client(client)
    
    def set_redis_client(self, client):
        """è®¾ç½® Redis å®¢æˆ·ç«¯"""
        self.cache.set_client(client)
    
    def _fetch_from_eastmoney(self, date: str = None, stock_code: str = None, page_size: int = 500) -> List[ShortSellingRecord]:
        """
        ä»ä¸œæ–¹è´¢å¯Œ API è·å–æ²½ç©ºæ•°æ®
        
        Args:
            date: æ—¥æœŸ (YYYY-MM-DD)ï¼Œä¸º None æ—¶è·å–æœ€æ–°æ•°æ®
            stock_code: è‚¡ç¥¨ä»£ç ï¼Œä¸º None æ—¶è·å–æ‰€æœ‰è‚¡ç¥¨
            page_size: æ¯é¡µæ•°é‡
            
        Returns:
            æ²½ç©ºè®°å½•åˆ—è¡¨
        """
        records = []
        now = datetime.now()
        
        try:
            # æ„å»ºè¯·æ±‚å‚æ•°
            params = {
                "sortColumns": "TRADE_DATE,SHORT_SELLING_RATIO",
                "sortTypes": "-1,-1",
                "pageSize": page_size,
                "pageNumber": 1,
                "reportName": "RPT_HK_SHORTSELLING",
                "columns": "ALL"
            }
            
            # æ·»åŠ è¿‡æ»¤æ¡ä»¶
            filters = []
            if date:
                # æ ¼å¼åŒ–æ—¥æœŸä¸ºä¸œæ–¹è´¢å¯Œæ ¼å¼
                filters.append(f'(TRADE_DATE=\'{date}\')')
            if stock_code:
                normalized_code = stock_code.zfill(5)
                filters.append(f'(SECURITY_CODE="{normalized_code}")')
            
            if filters:
                params["filter"] = "".join(filters)
            
            # é€Ÿç‡é™åˆ¶
            self.rate_limiter.acquire()
            
            logger.info(f"ğŸ”„ [ä¸œæ–¹è´¢å¯Œ] è·å–æ²½ç©ºæ•°æ®: date={date}, stock={stock_code}")
            
            response = requests.get(
                self.EASTMONEY_API,
                params=params,
                headers=self.headers,
                timeout=self.timeout
            )
            
            if response.status_code != 200:
                logger.warning(f"âš ï¸ [ä¸œæ–¹è´¢å¯Œ] HTTP {response.status_code}")
                return records
            
            data = response.json()
            
            if not data.get("success") or not data.get("result"):
                logger.warning(f"âš ï¸ [ä¸œæ–¹è´¢å¯Œ] API è¿”å›å¤±è´¥: {data.get('message')}")
                return records
            
            result_data = data["result"].get("data", [])
            
            for item in result_data:
                try:
                    # è§£ææ—¥æœŸ
                    trade_date = item.get("TRADE_DATE", "")
                    if trade_date:
                        trade_date = trade_date.split(" ")[0]  # å»æ‰æ—¶é—´éƒ¨åˆ†
                    
                    # æ²½ç©ºæ¯”ä¾‹ï¼ˆä¸œæ–¹è´¢å¯Œè¿”å›çš„æ˜¯ç™¾åˆ†æ¯”ï¼Œéœ€è¦è½¬æ¢ä¸ºå°æ•°ï¼‰
                    short_ratio = item.get("SHORT_SELLING_RATIO", 0)
                    if short_ratio:
                        short_ratio = float(short_ratio) / 100.0
                    
                    record = ShortSellingRecord(
                        stock_code=item.get("SECURITY_CODE", "").zfill(5),
                        stock_name=item.get("SECURITY_NAME_ABBR", ""),
                        date=trade_date,
                        short_shares=int(item.get("SHORT_SELLING_SHARES", 0) or 0),
                        short_value=float(item.get("SHORT_SELLING_AMT", 0) or 0),
                        short_ratio=short_ratio,
                        created_at=now,
                        updated_at=now
                    )
                    records.append(record)
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ [ä¸œæ–¹è´¢å¯Œ] è§£æè®°å½•å¤±è´¥: {e}")
                    continue
            
            logger.info(f"âœ… [ä¸œæ–¹è´¢å¯Œ] è·å–åˆ° {len(records)} æ¡è®°å½•")
            
        except Exception as e:
            logger.error(f"âŒ [ä¸œæ–¹è´¢å¯Œ] è·å–å¤±è´¥: {e}")
        
        return records
    
    def _format_date_for_url(self, date: str) -> str:
        """å°†æ—¥æœŸæ ¼å¼åŒ–ä¸º URL æ‰€éœ€æ ¼å¼ (YYYYMMDD)"""
        return date.replace("-", "")
    
    def _fetch_html(self, date: str) -> Optional[str]:
        """
        ä»æ¸¯äº¤æ‰€è·å– HTML å†…å®¹
        
        Args:
            date: æ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            HTML å†…å®¹ï¼Œå¤±è´¥è¿”å› None
        """
        url_date = self._format_date_for_url(date)
        urls = [
            self.HKEX_URL_TEMPLATE.format(date=url_date),
            self.HKEX_URL_TEMPLATE_ALT.format(date=url_date)
        ]
        
        for url in urls:
            for attempt in range(self.max_retries):
                try:
                    # é€Ÿç‡é™åˆ¶
                    self.rate_limiter.acquire()
                    
                    logger.info(f"ğŸ”„ [æ²½ç©ºæ•°æ®] è¯·æ±‚: {url} (å°è¯• {attempt + 1}/{self.max_retries})")
                    
                    response = requests.get(
                        url,
                        headers=self.headers,
                        timeout=self.timeout
                    )
                    
                    if response.status_code == 200:
                        logger.info(f"âœ… [æ²½ç©ºæ•°æ®] è·å–æˆåŠŸ: {date}")
                        return response.text
                    
                    elif response.status_code == 404:
                        logger.warning(f"âš ï¸ [æ²½ç©ºæ•°æ®] æ•°æ®ä¸å­˜åœ¨: {date}")
                        break  # å°è¯•ä¸‹ä¸€ä¸ª URL
                    
                    else:
                        logger.warning(f"âš ï¸ [æ²½ç©ºæ•°æ®] HTTP {response.status_code}: {url}")
                        
                except requests.exceptions.Timeout:
                    logger.warning(f"âš ï¸ [æ²½ç©ºæ•°æ®] è¯·æ±‚è¶…æ—¶: {url}")
                    
                except requests.exceptions.RequestException as e:
                    logger.warning(f"âš ï¸ [æ²½ç©ºæ•°æ®] è¯·æ±‚å¤±è´¥: {e}")
                
                # æŒ‡æ•°é€€é¿
                if attempt < self.max_retries - 1:
                    wait_time = (2 ** attempt) * 2
                    logger.debug(f"â±ï¸ [æ²½ç©ºæ•°æ®] ç­‰å¾… {wait_time} ç§’åé‡è¯•")
                    time.sleep(wait_time)
        
        logger.error(f"âŒ [æ²½ç©ºæ•°æ®] æ‰€æœ‰å°è¯•å‡å¤±è´¥: {date}")
        return None
    
    def fetch_daily_data(self, date: str) -> List[ShortSellingRecord]:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„æ²½ç©ºæ•°æ®
        
        æ•°æ®æºä¼˜å…ˆçº§ï¼š
        1. ä¸œæ–¹è´¢å¯Œ APIï¼ˆä¸»è¦æ•°æ®æºï¼‰
        2. æ¸¯äº¤æ‰€å®˜ç½‘ï¼ˆå¤‡ç”¨æ•°æ®æºï¼‰
        
        Args:
            date: æ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            æ²½ç©ºè®°å½•åˆ—è¡¨
        """
        records = []
        
        # ä¼˜å…ˆä½¿ç”¨ä¸œæ–¹è´¢å¯Œ API
        logger.info(f"ğŸ“Š [æ²½ç©ºæ•°æ®] è·å– {date} çš„æ•°æ®...")
        records = self._fetch_from_eastmoney(date=date)
        
        # å¦‚æœä¸œæ–¹è´¢å¯Œå¤±è´¥ï¼Œå°è¯•æ¸¯äº¤æ‰€
        if not records:
            logger.info(f"ğŸ”„ [æ²½ç©ºæ•°æ®] ä¸œæ–¹è´¢å¯Œæ— æ•°æ®ï¼Œå°è¯•æ¸¯äº¤æ‰€...")
            html_content = self._fetch_html(date)
            if html_content:
                records = self.parser.parse(html_content, date)
        
        if records:
            # å­˜å‚¨åˆ° MongoDB
            self.repository.upsert_records(records)
            
            # æ¸…é™¤ç›¸å…³ç¼“å­˜
            self.cache.invalidate_date(date)
            
            logger.info(f"âœ… [æ²½ç©ºæ•°æ®] {date}: è·å–å¹¶å­˜å‚¨ {len(records)} æ¡è®°å½•")
        else:
            logger.warning(f"âš ï¸ [æ²½ç©ºæ•°æ®] {date}: æœªè·å–åˆ°æ•°æ®")
        
        return records
    
    def get_stock_short_data(self, stock_code: str, date: str) -> Optional[Dict]:
        """
        è·å–ç‰¹å®šè‚¡ç¥¨åœ¨ç‰¹å®šæ—¥æœŸçš„æ²½ç©ºæ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            date: æ—¥æœŸ
            
        Returns:
            æ²½ç©ºæ•°æ®å­—å…¸æˆ– None
        """
        normalized_code = stock_code.zfill(5)
        
        # å…ˆæŸ¥ç¼“å­˜
        cached = self.cache.get_stock_data(normalized_code, date)
        if cached:
            logger.debug(f"âš¡ [æ²½ç©ºæ•°æ®] ç¼“å­˜å‘½ä¸­: {normalized_code} @ {date}")
            return cached
        
        # æŸ¥æ•°æ®åº“
        data = self.repository.find_by_stock_and_date(normalized_code, date)
        
        if data:
            # å†™å…¥ç¼“å­˜
            self.cache.set_stock_data(normalized_code, date, data)
        
        return data
    
    def get_stock_short_history(
        self, 
        stock_code: str, 
        start_date: str, 
        end_date: str
    ) -> List[Dict]:
        """
        è·å–è‚¡ç¥¨çš„æ²½ç©ºå†å²æ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            æ²½ç©ºè®°å½•åˆ—è¡¨
        """
        return self.repository.find_by_stock_and_date_range(
            stock_code, start_date, end_date
        )
    
    def get_top_short_stocks(self, date: str, top_n: int = 20) -> List[Dict]:
        """
        è·å–æŒ‡å®šæ—¥æœŸæ²½ç©ºæ¯”ä¾‹æœ€é«˜çš„è‚¡ç¥¨
        
        Args:
            date: æ—¥æœŸ
            top_n: è¿”å›æ•°é‡
            
        Returns:
            æŒ‰æ²½ç©ºæ¯”ä¾‹é™åºæ’åˆ—çš„è‚¡ç¥¨åˆ—è¡¨
        """
        # å…ˆæŸ¥ç¼“å­˜
        cached = self.cache.get_top_stocks(date, top_n)
        if cached:
            return cached
        
        # æŸ¥æ•°æ®åº“
        stocks = self.repository.find_top_by_ratio(date, top_n)
        
        if stocks:
            # å†™å…¥ç¼“å­˜
            self.cache.set_top_stocks(date, top_n, stocks)
        
        return stocks
    
    def get_market_short_stats(self, date: str) -> Optional[Dict]:
        """
        è·å–å…¨å¸‚åœºæ²½ç©ºç»Ÿè®¡
        
        Args:
            date: æ—¥æœŸ
            
        Returns:
            å¸‚åœºç»Ÿè®¡æ•°æ®
        """
        # å…ˆæŸ¥ç¼“å­˜
        cached = self.cache.get_daily_stats(date)
        if cached:
            return cached
        
        # æŸ¥æ•°æ®åº“
        stats = self.repository.get_market_stats(date)
        
        if stats:
            # å†™å…¥ç¼“å­˜
            self.cache.set_daily_stats(date, stats)
        
        return stats
    
    def backfill_history(
        self, 
        start_date: str, 
        end_date: str, 
        force: bool = False,
        progress_callback: Optional[Callable[[str, int, int], None]] = None
    ) -> Dict:
        """
        å›å¡«å†å²æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            force: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°å·²æœ‰æ•°æ®
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (date, current, total)
            
        Returns:
            å›å¡«ç»“æœç»Ÿè®¡
        """
        result = {
            "success": True,
            "start_date": start_date,
            "end_date": end_date,
            "total_dates": 0,
            "processed_dates": 0,
            "skipped_dates": 0,
            "failed_dates": [],
            "total_records": 0
        }
        
        # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨
        start = datetime.strptime(start_date, "%Y-%m-%d")
        end = datetime.strptime(end_date, "%Y-%m-%d")
        
        dates = []
        current = start
        while current <= end:
            # è·³è¿‡å‘¨æœ«
            if current.weekday() < 5:
                dates.append(current.strftime("%Y-%m-%d"))
            current += timedelta(days=1)
        
        result["total_dates"] = len(dates)
        
        # è·å–å·²æœ‰æ•°æ®çš„æ—¥æœŸ
        existing_dates = set()
        if not force:
            existing_dates = self.repository.get_dates_with_data(start_date, end_date)
        
        # é€æ—¥å¤„ç†
        for i, date in enumerate(dates):
            if progress_callback:
                progress_callback(date, i + 1, len(dates))
            
            # è·³è¿‡å·²æœ‰æ•°æ®
            if date in existing_dates:
                logger.info(f"â­ï¸ [å›å¡«] è·³è¿‡å·²æœ‰æ•°æ®: {date}")
                result["skipped_dates"] += 1
                continue
            
            try:
                records = self.fetch_daily_data(date)
                result["processed_dates"] += 1
                result["total_records"] += len(records)
                
                logger.info(f"âœ… [å›å¡«] {date}: {len(records)} æ¡è®°å½•")
                
            except Exception as e:
                logger.error(f"âŒ [å›å¡«] {date} å¤±è´¥: {e}")
                result["failed_dates"].append(date)
        
        if result["failed_dates"]:
            result["success"] = False
        
        return result


# ============================================================================
# å®šæ—¶è°ƒåº¦å™¨
# ============================================================================

class ShortSellingScheduler:
    """æ²½ç©ºæ•°æ®é‡‡é›†å®šæ—¶è°ƒåº¦å™¨"""
    
    # é¦™æ¸¯å…¬ä¼—å‡æœŸï¼ˆéœ€è¦å®šæœŸæ›´æ–°ï¼‰
    HK_HOLIDAYS_2024 = {
        "2024-01-01", "2024-02-10", "2024-02-11", "2024-02-12", "2024-02-13",
        "2024-03-29", "2024-04-01", "2024-04-04", "2024-05-01", "2024-05-15",
        "2024-06-10", "2024-07-01", "2024-09-18", "2024-10-01", "2024-10-11",
        "2024-12-25", "2024-12-26"
    }
    
    HK_HOLIDAYS_2025 = {
        "2025-01-01", "2025-01-29", "2025-01-30", "2025-01-31",
        "2025-04-04", "2025-04-18", "2025-04-21", "2025-05-01", "2025-05-05",
        "2025-05-31", "2025-07-01", "2025-10-01", "2025-10-07",
        "2025-12-25", "2025-12-26"
    }
    
    HK_HOLIDAYS_2026 = {
        "2026-01-01", "2026-02-17", "2026-02-18", "2026-02-19",
        "2026-04-03", "2026-04-06", "2026-04-25", "2026-05-01", "2026-05-24",
        "2026-06-19", "2026-07-01", "2026-10-01", "2026-10-26",
        "2026-12-25", "2026-12-26"
    }
    
    def __init__(self, provider: HKShortSellingProvider):
        """
        åˆå§‹åŒ–è°ƒåº¦å™¨
        
        Args:
            provider: æ²½ç©ºæ•°æ®æä¾›å™¨
        """
        self.provider = provider
        self.scheduler = None
        self._running = False
        
        # åˆå¹¶æ‰€æœ‰å‡æœŸ
        self.holidays = (
            self.HK_HOLIDAYS_2024 | 
            self.HK_HOLIDAYS_2025 | 
            self.HK_HOLIDAYS_2026
        )
    
    def start(self) -> None:
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self._running:
            logger.warning("âš ï¸ [è°ƒåº¦å™¨] å·²åœ¨è¿è¡Œä¸­")
            return
        
        try:
            from apscheduler.schedulers.background import BackgroundScheduler
            from apscheduler.triggers.cron import CronTrigger
            
            self.scheduler = BackgroundScheduler(timezone="Asia/Hong_Kong")
            
            # æ¯ä¸ªäº¤æ˜“æ—¥ 18:00 æ‰§è¡Œï¼ˆæ”¶å¸‚åï¼‰
            trigger = CronTrigger(
                hour=18,
                minute=0,
                day_of_week="mon-fri",
                timezone="Asia/Hong_Kong"
            )
            
            self.scheduler.add_job(
                self._daily_job,
                trigger=trigger,
                id="hk_short_selling_daily",
                name="æ¸¯è‚¡æ²½ç©ºæ•°æ®æ¯æ—¥é‡‡é›†"
            )
            
            self.scheduler.start()
            self._running = True
            
            logger.info("âœ… [è°ƒåº¦å™¨] å·²å¯åŠ¨ï¼Œæ¯ä¸ªäº¤æ˜“æ—¥ 18:00 æ‰§è¡Œ")
            
        except ImportError:
            logger.error("âŒ [è°ƒåº¦å™¨] éœ€è¦å®‰è£… apscheduler: pip install apscheduler")
        except Exception as e:
            logger.error(f"âŒ [è°ƒåº¦å™¨] å¯åŠ¨å¤±è´¥: {e}")
    
    def stop(self) -> None:
        """åœæ­¢è°ƒåº¦å™¨"""
        if self.scheduler and self._running:
            self.scheduler.shutdown()
            self._running = False
            logger.info("âœ… [è°ƒåº¦å™¨] å·²åœæ­¢")
    
    def trigger_now(self) -> Dict:
        """
        ç«‹å³è§¦å‘é‡‡é›†ä»»åŠ¡
        
        Returns:
            é‡‡é›†ç»“æœ
        """
        return self._daily_job()
    
    def _is_trading_day(self, date: datetime) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
        
        Args:
            date: æ—¥æœŸ
            
        Returns:
            æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
        """
        # å‘¨æœ«ä¸æ˜¯äº¤æ˜“æ—¥
        if date.weekday() >= 5:
            return False
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå‡æœŸ
        date_str = date.strftime("%Y-%m-%d")
        if date_str in self.holidays:
            return False
        
        return True
    
    def _daily_job(self) -> Dict:
        """
        æ¯æ—¥é‡‡é›†ä»»åŠ¡
        
        Returns:
            é‡‡é›†ç»“æœ
        """
        today = datetime.now()
        date_str = today.strftime("%Y-%m-%d")
        
        result = {
            "date": date_str,
            "success": False,
            "is_trading_day": False,
            "records_count": 0,
            "error": None
        }
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
        if not self._is_trading_day(today):
            logger.info(f"â„¹ï¸ [æ¯æ—¥é‡‡é›†] {date_str} ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œè·³è¿‡")
            result["is_trading_day"] = False
            result["success"] = True
            return result
        
        result["is_trading_day"] = True
        
        try:
            records = self.provider.fetch_daily_data(date_str)
            result["records_count"] = len(records)
            result["success"] = True
            
            logger.info(f"âœ… [æ¯æ—¥é‡‡é›†] {date_str}: {len(records)} æ¡è®°å½•")
            
        except Exception as e:
            result["error"] = str(e)
            logger.error(f"âŒ [æ¯æ—¥é‡‡é›†] {date_str} å¤±è´¥: {e}")
        
        return result


# ============================================================================
# é£æ§åˆ†æå·¥å…·
# ============================================================================

def get_short_selling_risk_analysis(
    provider: HKShortSellingProvider,
    stock_code: str,
    date: str = None,
    risk_threshold: float = 0.10,
    history_days: int = 20
) -> Dict:
    """
    è·å–æ²½ç©ºæ•°æ®é£é™©åˆ†æ
    
    Args:
        provider: æ²½ç©ºæ•°æ®æä¾›å™¨
        stock_code: è‚¡ç¥¨ä»£ç 
        date: åˆ†ææ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
        risk_threshold: é£é™©é˜ˆå€¼ï¼ˆé»˜è®¤ 10%ï¼‰
        history_days: å†å²æ•°æ®å¤©æ•°
        
    Returns:
        é£é™©åˆ†æç»“æœ
    """
    if date is None:
        date = datetime.now().strftime("%Y-%m-%d")
    
    normalized_code = stock_code.zfill(5)
    
    result = {
        "stock_code": normalized_code,
        "date": date,
        "has_data": False,
        "current_ratio": None,
        "is_high_risk": False,
        "risk_level": "æœªçŸ¥",
        "trend": "æœªçŸ¥",
        "trend_description": "",
        "history_avg": None,
        "history_max": None,
        "history_min": None,
        "analysis_text": ""
    }
    
    # è·å–å½“æ—¥æ•°æ®
    current_data = provider.get_stock_short_data(normalized_code, date)
    
    if not current_data:
        result["analysis_text"] = f"âš ï¸ æœªæ‰¾åˆ° {normalized_code} åœ¨ {date} çš„æ²½ç©ºæ•°æ®"
        return result
    
    result["has_data"] = True
    result["current_ratio"] = current_data.get("short_ratio", 0)
    
    # åˆ¤æ–­æ˜¯å¦é«˜é£é™©
    current_ratio = result["current_ratio"]
    result["is_high_risk"] = current_ratio > risk_threshold
    
    # é£é™©ç­‰çº§
    if current_ratio > 0.30:
        result["risk_level"] = "æé«˜"
    elif current_ratio > 0.20:
        result["risk_level"] = "é«˜"
    elif current_ratio > risk_threshold:
        result["risk_level"] = "ä¸­ç­‰"
    else:
        result["risk_level"] = "ä½"
    
    # è·å–å†å²æ•°æ®è®¡ç®—è¶‹åŠ¿
    end_date = datetime.strptime(date, "%Y-%m-%d")
    start_date = end_date - timedelta(days=history_days)
    
    history = provider.get_stock_short_history(
        normalized_code,
        start_date.strftime("%Y-%m-%d"),
        date
    )
    
    if history and len(history) > 1:
        ratios = [h.get("short_ratio", 0) for h in history]
        result["history_avg"] = sum(ratios) / len(ratios)
        result["history_max"] = max(ratios)
        result["history_min"] = min(ratios)
        
        # è®¡ç®—è¶‹åŠ¿
        avg = result["history_avg"]
        if avg > 0:
            ratio_to_avg = current_ratio / avg
            
            if ratio_to_avg > 1.10:
                result["trend"] = "ä¸Šå‡"
                result["trend_description"] = f"å½“å‰æ²½ç©ºæ¯”ä¾‹é«˜äºå†å²å¹³å‡ {(ratio_to_avg - 1) * 100:.1f}%"
            elif ratio_to_avg < 0.90:
                result["trend"] = "ä¸‹é™"
                result["trend_description"] = f"å½“å‰æ²½ç©ºæ¯”ä¾‹ä½äºå†å²å¹³å‡ {(1 - ratio_to_avg) * 100:.1f}%"
            else:
                result["trend"] = "ç¨³å®š"
                result["trend_description"] = "å½“å‰æ²½ç©ºæ¯”ä¾‹æ¥è¿‘å†å²å¹³å‡æ°´å¹³"
    
    # ç”Ÿæˆåˆ†ææ–‡æœ¬
    analysis_lines = [
        f"## æ²½ç©ºé£é™©åˆ†æ - {normalized_code}",
        f"",
        f"**åˆ†ææ—¥æœŸ**: {date}",
        f"**å½“å‰æ²½ç©ºæ¯”ä¾‹**: {current_ratio * 100:.2f}%",
        f"**é£é™©ç­‰çº§**: {result['risk_level']}",
        f"**è¶‹åŠ¿**: {result['trend']}",
    ]
    
    if result["history_avg"]:
        analysis_lines.extend([
            f"",
            f"### å†å²æ•°æ®ï¼ˆè¿‘ {history_days} å¤©ï¼‰",
            f"- å¹³å‡æ²½ç©ºæ¯”ä¾‹: {result['history_avg'] * 100:.2f}%",
            f"- æœ€é«˜æ²½ç©ºæ¯”ä¾‹: {result['history_max'] * 100:.2f}%",
            f"- æœ€ä½æ²½ç©ºæ¯”ä¾‹: {result['history_min'] * 100:.2f}%",
        ])
    
    if result["is_high_risk"]:
        analysis_lines.extend([
            f"",
            f"### âš ï¸ é£é™©æç¤º",
            f"å½“å‰æ²½ç©ºæ¯”ä¾‹ ({current_ratio * 100:.2f}%) è¶…è¿‡é£é™©é˜ˆå€¼ ({risk_threshold * 100:.0f}%)ï¼Œ",
            f"å»ºè®®å…³æ³¨å¸‚åœºæƒ…ç»ªå˜åŒ–å’Œæ½œåœ¨ä¸‹è¡Œé£é™©ã€‚"
        ])
    
    if result["trend_description"]:
        analysis_lines.extend([
            f"",
            f"### è¶‹åŠ¿åˆ†æ",
            result["trend_description"]
        ])
    
    result["analysis_text"] = "\n".join(analysis_lines)
    
    return result


def get_short_selling_market_analysis(
    provider: HKShortSellingProvider,
    stock_code: str,
    date: str = None,
    history_days: int = 20
) -> Dict:
    """
    è·å–æ²½ç©ºæ•°æ®å¸‚åœºåˆ†æï¼ˆä¾›åˆ†æå¸ˆä»£ç†ä½¿ç”¨ï¼‰
    
    Args:
        provider: æ²½ç©ºæ•°æ®æä¾›å™¨
        stock_code: è‚¡ç¥¨ä»£ç 
        date: åˆ†ææ—¥æœŸ
        history_days: å†å²æ•°æ®å¤©æ•°
        
    Returns:
        å¸‚åœºåˆ†æç»“æœ
    """
    if date is None:
        date = datetime.now().strftime("%Y-%m-%d")
    
    normalized_code = stock_code.zfill(5)
    
    result = {
        "stock_code": normalized_code,
        "date": date,
        "has_data": False,
        "short_shares": None,
        "short_value": None,
        "short_ratio": None,
        "trend": "æœªçŸ¥",
        "market_sentiment": "ä¸­æ€§",
        "sentiment_score": 0,
        "top_rank": None,
        "analysis_text": ""
    }
    
    # è·å–å½“æ—¥æ•°æ®
    current_data = provider.get_stock_short_data(normalized_code, date)
    
    if not current_data:
        result["analysis_text"] = f"âš ï¸ æœªæ‰¾åˆ° {normalized_code} åœ¨ {date} çš„æ²½ç©ºæ•°æ®"
        return result
    
    result["has_data"] = True
    result["short_shares"] = current_data.get("short_shares", 0)
    result["short_value"] = current_data.get("short_value", 0)
    result["short_ratio"] = current_data.get("short_ratio", 0)
    
    # è·å– Top æ’å
    top_stocks = provider.get_top_short_stocks(date, 50)
    for i, stock in enumerate(top_stocks):
        if stock.get("stock_code") == normalized_code:
            result["top_rank"] = i + 1
            break
    
    # è·å–å†å²æ•°æ®è®¡ç®—è¶‹åŠ¿
    end_date = datetime.strptime(date, "%Y-%m-%d")
    start_date = end_date - timedelta(days=history_days)
    
    history = provider.get_stock_short_history(
        normalized_code,
        start_date.strftime("%Y-%m-%d"),
        date
    )
    
    current_ratio = result["short_ratio"]
    
    if history and len(history) > 1:
        ratios = [h.get("short_ratio", 0) for h in history]
        avg_ratio = sum(ratios) / len(ratios)
        
        if avg_ratio > 0:
            ratio_to_avg = current_ratio / avg_ratio
            
            if ratio_to_avg > 1.10:
                result["trend"] = "ä¸Šå‡"
            elif ratio_to_avg < 0.90:
                result["trend"] = "ä¸‹é™"
            else:
                result["trend"] = "ç¨³å®š"
    
    # è®¡ç®—å¸‚åœºæƒ…ç»ª
    # æ²½ç©ºæ¯”ä¾‹è¶Šé«˜ï¼Œçœ‹ç©ºæƒ…ç»ªè¶Šå¼º
    if current_ratio > 0.25:
        result["market_sentiment"] = "å¼ºçƒˆçœ‹ç©º"
        result["sentiment_score"] = -2
    elif current_ratio > 0.15:
        result["market_sentiment"] = "åç©º"
        result["sentiment_score"] = -1
    elif current_ratio > 0.08:
        result["market_sentiment"] = "ä¸­æ€§"
        result["sentiment_score"] = 0
    elif current_ratio > 0.03:
        result["market_sentiment"] = "åå¤š"
        result["sentiment_score"] = 1
    else:
        result["market_sentiment"] = "å¼ºçƒˆçœ‹å¤š"
        result["sentiment_score"] = 2
    
    # ç”Ÿæˆåˆ†ææ–‡æœ¬
    analysis_lines = [
        f"## æ²½ç©ºå¸‚åœºåˆ†æ - {normalized_code}",
        f"",
        f"**åˆ†ææ—¥æœŸ**: {date}",
        f"",
        f"### æ²½ç©ºæŒ‡æ ‡",
        f"- æ²½ç©ºè‚¡æ•°: {result['short_shares']:,} è‚¡",
        f"- æ²½ç©ºé‡‘é¢: HK${result['short_value']:,.2f}",
        f"- æ²½ç©ºæ¯”ä¾‹: {current_ratio * 100:.2f}%",
    ]
    
    if result["top_rank"]:
        analysis_lines.append(f"- æ²½ç©ºæ’å: ç¬¬ {result['top_rank']} å")
    
    analysis_lines.extend([
        f"",
        f"### å¸‚åœºæƒ…ç»ª",
        f"- æƒ…ç»ªåˆ¤æ–­: {result['market_sentiment']}",
        f"- è¶‹åŠ¿æ–¹å‘: {result['trend']}",
    ])
    
    # æƒ…ç»ªè§£è¯»
    sentiment_interpretation = {
        "å¼ºçƒˆçœ‹ç©º": "å¸‚åœºå¯¹è¯¥è‚¡ç¥¨æŒå¼ºçƒˆçœ‹ç©ºæ€åº¦ï¼Œæ²½ç©ºæ´»åŠ¨éå¸¸æ´»è·ƒï¼Œéœ€è­¦æƒ•ä¸‹è¡Œé£é™©ã€‚",
        "åç©º": "å¸‚åœºå¯¹è¯¥è‚¡ç¥¨åå‘çœ‹ç©ºï¼Œæ²½ç©ºæ¯”ä¾‹è¾ƒé«˜ï¼Œå»ºè®®è°¨æ…æ“ä½œã€‚",
        "ä¸­æ€§": "å¸‚åœºå¯¹è¯¥è‚¡ç¥¨æ€åº¦ä¸­æ€§ï¼Œæ²½ç©ºæ´»åŠ¨å¤„äºæ­£å¸¸æ°´å¹³ã€‚",
        "åå¤š": "å¸‚åœºå¯¹è¯¥è‚¡ç¥¨åå‘çœ‹å¤šï¼Œæ²½ç©ºæ¯”ä¾‹è¾ƒä½ï¼Œå¸‚åœºæƒ…ç»ªç›¸å¯¹ä¹è§‚ã€‚",
        "å¼ºçƒˆçœ‹å¤š": "å¸‚åœºå¯¹è¯¥è‚¡ç¥¨æŒå¼ºçƒˆçœ‹å¤šæ€åº¦ï¼Œæ²½ç©ºæ´»åŠ¨å¾ˆå°‘ï¼Œå¸‚åœºæƒ…ç»ªéå¸¸ä¹è§‚ã€‚"
    }
    
    analysis_lines.extend([
        f"",
        f"### æƒ…ç»ªè§£è¯»",
        sentiment_interpretation.get(result["market_sentiment"], "")
    ])
    
    result["analysis_text"] = "\n".join(analysis_lines)
    
    return result


# ============================================================================
# å…¨å±€å®ä¾‹å’Œä¾¿æ·å‡½æ•°
# ============================================================================

_provider_instance: Optional[HKShortSellingProvider] = None
_scheduler_instance: Optional[ShortSellingScheduler] = None


def get_short_selling_provider() -> HKShortSellingProvider:
    """è·å–æ²½ç©ºæ•°æ®æä¾›å™¨å…¨å±€å®ä¾‹"""
    global _provider_instance
    if _provider_instance is None:
        _provider_instance = HKShortSellingProvider()
    return _provider_instance


def get_short_selling_scheduler() -> ShortSellingScheduler:
    """è·å–æ²½ç©ºæ•°æ®è°ƒåº¦å™¨å…¨å±€å®ä¾‹"""
    global _scheduler_instance
    if _scheduler_instance is None:
        _scheduler_instance = ShortSellingScheduler(get_short_selling_provider())
    return _scheduler_instance


def init_short_selling_module(mongodb_client=None, redis_client=None):
    """
    åˆå§‹åŒ–æ²½ç©ºæ•°æ®æ¨¡å—
    
    Args:
        mongodb_client: MongoDB å®¢æˆ·ç«¯
        redis_client: Redis å®¢æˆ·ç«¯
    """
    provider = get_short_selling_provider()
    
    if mongodb_client:
        provider.set_mongodb_client(mongodb_client)
    
    if redis_client:
        provider.set_redis_client(redis_client)
    
    logger.info("âœ… [æ²½ç©ºæ¨¡å—] åˆå§‹åŒ–å®Œæˆ")


# ä¾¿æ·å‡½æ•°
def fetch_short_selling_data(date: str) -> List[ShortSellingRecord]:
    """è·å–æŒ‡å®šæ—¥æœŸçš„æ²½ç©ºæ•°æ®"""
    return get_short_selling_provider().fetch_daily_data(date)


def get_stock_short_info(stock_code: str, date: str = None) -> Optional[Dict]:
    """è·å–è‚¡ç¥¨æ²½ç©ºä¿¡æ¯"""
    if date is None:
        date = datetime.now().strftime("%Y-%m-%d")
    return get_short_selling_provider().get_stock_short_data(stock_code, date)


def get_top_short_stocks(date: str = None, top_n: int = 20) -> List[Dict]:
    """è·å–æ²½ç©ºæ¯”ä¾‹æœ€é«˜çš„è‚¡ç¥¨"""
    if date is None:
        date = datetime.now().strftime("%Y-%m-%d")
    return get_short_selling_provider().get_top_short_stocks(date, top_n)


def analyze_short_selling_risk(stock_code: str, date: str = None) -> Dict:
    """åˆ†æè‚¡ç¥¨æ²½ç©ºé£é™©"""
    return get_short_selling_risk_analysis(
        get_short_selling_provider(),
        stock_code,
        date
    )


def analyze_short_selling_market(stock_code: str, date: str = None) -> Dict:
    """åˆ†æè‚¡ç¥¨æ²½ç©ºå¸‚åœºæƒ…ç»ª"""
    return get_short_selling_market_analysis(
        get_short_selling_provider(),
        stock_code,
        date
    )


# æ¨¡å—å¯¼å‡º
__all__ = [
    # æ•°æ®æ¨¡å‹
    "ShortSellingRecord",
    
    # æ ¸å¿ƒç»„ä»¶
    "HKEXShortSellingParser",
    "ShortSellingRepository",
    "ShortSellingCache",
    "RateLimiter",
    "HKShortSellingProvider",
    "ShortSellingScheduler",
    
    # åˆ†æå‡½æ•°
    "get_short_selling_risk_analysis",
    "get_short_selling_market_analysis",
    
    # å…¨å±€å®ä¾‹
    "get_short_selling_provider",
    "get_short_selling_scheduler",
    "init_short_selling_module",
    
    # ä¾¿æ·å‡½æ•°
    "fetch_short_selling_data",
    "get_stock_short_info",
    "get_top_short_stocks",
    "analyze_short_selling_risk",
    "analyze_short_selling_market",
]
